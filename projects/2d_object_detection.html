<!DOCTYPE html><html lang="en" class="h-100"><head>
    <title>VUNDER Lab</title>
    <meta charset="UTF-8">
    <meta name="description" content="VUNDER Lab Webpage">
    <meta name="keywords" content="SAIC Moscow,VUNDER,Computer Vision">
    <meta name="author" content="Anna Vorontsova">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="../css/bootstrap/bootstrap.min.css">
    <link rel="stylesheet" type="text/css" href="../css/styles.css">
</head>

<body class="h-100">
    <div class="vunder-cover-container">
        <img class="vunder-cover-image" src="../img/covers/2d_object_detection.png" alt="2D Object Detection project cover"> </img>
        <div class="vunder-cover-link-div"> <a class="vunder-cover-link" href="../projects.html"> Back to projects </a> </div> 
        <div class="vunder-cover-text">
            <p class="vunder-project-title"> 2D Object Detection</p>
            <br>
            <p class="vunder-topic"> #2d_object_detection </p>
        </div>
    </div>
    <main class="vunder-main">
        <h1></h1>

        <p>Deep learning-based detectors usually produce a redundant set of object bounding boxes, including many duplicate detections of the same object. These boxes are then filtered using non-maximum suppression (NMS) to select exactly one bounding box per object of interest. This greedy scheme is simple and provides sufficient accuracy for isolated objects but often fails in crowded environments: one must preserve boxes for different objects and suppress duplicate detections at the same time. </p> 

        <p> We developed <text class="vunder-project-color bold"> Iterdet, an iterative object detection scheme </text> where a new subset of objects is detected at each iteration. Detected boxes from the previous iterations are passed to the network at the following iterations to ensure that the same object would not be detected twice. This iterative scheme can be applied to both one-stage and two-stage object detectors with just minor training and inference modifications. We perform extensive experiments with two different baseline detectors on four datasets and show significant improvement over the baseline, leading to state-of-the-art performance on CrowdHuman and WiderPerson datasets. </p>

        <h1> Publications </h1>

        <div class="vunder-pub" id="pub-rukhovich2021iterdet-id">
            <span class="vunder-pub-title">IterDet: Iterative Scheme for Object Detection in Crowded Environments</span>
            <span class="vunder-pub-author">Danila Rukhovich, Konstantin Sofiiuk, Danil Galeev, Olga Barinova, Anton Konushin.</span>
            <span class="vunder-pub-channel">Proc. of the Structural, Syntactic, and Statistical Pattern Recognition: Joint IAPR International Workshops (S+ SSPR)</span>
            <span class="vunder-pub-year">2020</span>
            <div class="vunder-pub-link-group">
                <a class="vunder-pub-link vunder-project-color" href="https://arxiv.org/abs/2005.05708">PDF</a>
                <a class="vunder-pub-link vunder-project-color" href="https://github.com/saic-vul/iterdet">Code</a>
                <a class="vunder-pub-link vunder-project-color" aria-controls="bib-rukhovich2021iterdet-id" aria-expanded="false" data-toggle="collapse" href="#bib-rukhovich2021iterdet-id">BibTeX</a>
            </div>
            <pre class="collapse vunder-pub-bibtex" id="bib-rukhovich2021iterdet-id">
                @inproceedings{rukhovich2021iterdet,
                  title={IterDet: Iterative Scheme for Object Detection in Crowded Environments},
                  author={Danila Rukhovich, Konstantin Sofiiuk, Danil Galeev, Olga Barinova, Anton Konushin},
                  booktitle={Structural, Syntactic, and Statistical Pattern Recognition: Joint IAPR International Workshops, S+ SSPR 2020, Padua, Italy, January 21--22, 2021, Proceedings},
                  pages={344},
                  organization={Springer Nature}
                }
            </pre>
        </div>

    </main>
    <footer class="vunder-footer">
        <img class="vunder-footer-samsung" src="../img/samsung_logo.png" alt="SAMSUNG">
        <p class="vunder-footer-samsung-research">|</p> <p class="vunder-footer-samsung-research">Samsung Research</p> <p class="vunder-footer-samsung-research">|</p>
        <p class="vunder-footer-vunder">Vision Understanding Lab 2022 </p>
    </footer>
    <script src="../js/jquery.js"></script>
    <script src="../js/bootstrap/bootstrap.min.js"></script>
</body></html>